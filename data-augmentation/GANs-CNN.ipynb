{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIJ8Bhy3KaYm"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/khetansarvesh/CV/blob/main/data-augmentation/GANs-CNN.ipynb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a68hpbeSh5H"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torchvision\n",
        "from torchvision.utils import make_grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiX-VdQWcnml",
        "outputId": "8b36a0d2-4e45-4b6b-bb16-368c2a2d450a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "LATENT_DIM = 64 # noisy input dimentions\n",
        "IM_CHANNELS = 1 # no of channels in image = 1 cause black and white\n",
        "IM_SIZE = (28, 28)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJIBS7a8TK-O"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bgcpa614S5uT"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZZmQEvbjYGO",
        "outputId": "3b08e0bf-8a04-4056-e641-810c51e3a65a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 143039968.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 29035401.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1648877/1648877 [00:00<00:00, 39206178.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 7003870.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]) # Define the transformation to normalize the data between 1 and -1 (mean = 0.5 and variance = 0.5 will transform to values between 1 and -1)\n",
        "mnist = datasets.MNIST(root='./data', train=True, transform=transform, download=True) # downloading the MNIST train dataset and then applying some transformations\n",
        "mnist_loader = DataLoader(dataset=mnist, batch_size=64, shuffle=True) # loading the downloaded dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "_iNdQTrqlmLd",
        "outputId": "312309c0-fbaa-46aa-fb82-dd6f5ed1e3d9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Display one image from one of the batches\n",
        "images, labels = next(iter(mnist_loader)) # Extract one batch of images and labels\n",
        "image = images[0].numpy().squeeze() # loading the one image from that batch\n",
        "label = labels[0].item() # loading the actual label of the above image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.title(f\"Label: {label}\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNHZI1K6TOIE"
      },
      "source": [
        "# Modelling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self, latent_dim, im_size, im_channels):\n",
        "        super().__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.im_size = im_size\n",
        "        self.im_channels = im_channels\n",
        "\n",
        "        #encoder\n",
        "        self.encoder_layer_1 = nn.Sequential(nn.ConvTranspose2d(100, 512, kernel_size=4, stride=2, padding=1, output_padding=1, bias=False), nn.BatchNorm2d(512),nn.ReLU())\n",
        "        '''\n",
        "        ideally for encoder part instead of ConvTranspose2d we should use Conv2d but Conv2d does not work correctly, idk why, following is the code for Conv2d\n",
        "        self.encoder_layer_1 = nn.Sequential(nn.Conv2d(100, 128, kernel_size=2, stride=2, padding=1, bias=False), nn.BatchNorm2d(128),nn.ReLU())\n",
        "        self.encoder_layer_2 = nn.Sequential(nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1, bias=False), nn.BatchNorm2d(256),nn.ReLU())\n",
        "        self.encoder_layer_3 = nn.Sequential(nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1, bias=False), nn.BatchNorm2d(512),nn.ReLU())\n",
        "        '''\n",
        "        #decoder\n",
        "        self.decoder_layer_1 = nn.Sequential(nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, output_padding=1, bias=False), nn.BatchNorm2d(256),nn.ReLU())\n",
        "        self.decoder_layer_2 = nn.Sequential(nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, output_padding=0, bias=False), nn.BatchNorm2d(128),nn.ReLU())\n",
        "        self.decoder_layer_3 = nn.Sequential(nn.ConvTranspose2d(128, 1, kernel_size=4, stride=2, padding=1, output_padding=0, bias=False), nn.Identity(),nn.Tanh())\n",
        "\n",
        "    def forward(self, z):\n",
        "        batch_size = z.shape[0]\n",
        "        out = z.reshape(-1, self.latent_dim, 1, 1)\n",
        "\n",
        "        #encoder forward pass\n",
        "        out = self.encoder_layer_1(out)\n",
        "\n",
        "        #decoder forward pass\n",
        "        out = self.decoder_layer_1(out)\n",
        "        out = self.decoder_layer_2(out)\n",
        "        out = self.decoder_layer_3(out)\n",
        "\n",
        "        out = out.reshape(batch_size, self.im_channels, self.im_size, self.im_size)\n",
        "        return out"
      ],
      "metadata": {
        "id": "S8ugVET_GT9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxp6IHoYY-hZ"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        layer_1 = nn.Sequential(nn.Conv2d(1, 128, kernel_size=4, stride=2, padding=1, bias=True), nn.Identity(),nn.LeakyReLU())\n",
        "        layer_2 = nn.Sequential(nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False), nn.BatchNorm2d(256),nn.LeakyReLU())\n",
        "        layer_3 = nn.Sequential(nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False), nn.BatchNorm2d(512),nn.LeakyReLU())\n",
        "        layer_4 = nn.Sequential(nn.Conv2d(512, 1, kernel_size=4, stride=2, padding=1, bias=False), nn.Identity(),nn.Sigmoid())\n",
        "        self.layers = nn.ModuleList([layer_1, layer_2, layer_3, layer_4])\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x\n",
        "        for layer in self.layers:\n",
        "            out = layer(out)\n",
        "        return out.reshape(x.size(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_KJWVseZVD2"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmMlwBvJcu8o"
      },
      "outputs": [],
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "# Instantiate generator model\n",
        "im_channels = 1\n",
        "im_size = 28\n",
        "latent_dim = 100\n",
        "generator = Generator(latent_dim, im_size, im_channels).to(device)\n",
        "generator.train()\n",
        "optimizer_generator = Adam(generator.parameters(), lr=0.0005, betas=(0.5, 0.999)) #0.5 is momentum\n",
        "\n",
        "# Instantiate discriminator model\n",
        "discriminator = Discriminator().to(device)\n",
        "discriminator.train()\n",
        "optimizer_discriminator = Adam(discriminator.parameters(), lr=0.0005, betas=(0.5, 0.999)) #0.5 is momentum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bLLsW8LRjEL",
        "outputId": "fe1cd468-4005-4d76-d329-5605fa1b64b6"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 226/938 [09:54<34:49,  2.93s/it]"
          ]
        }
      ],
      "source": [
        "steps = 0\n",
        "\n",
        "for epoch in range(50): # for each epoch\n",
        "    generator_losses = []\n",
        "    discriminator_losses = []\n",
        "    mean_real_dis_preds = []\n",
        "    mean_fake_dis_preds = []\n",
        "\n",
        "    for im, _ in tqdm(mnist_loader): # for each image in each epoch\n",
        "\n",
        "        real_ims = im.float().to(device)\n",
        "        batch_size = real_ims.shape[0]\n",
        "\n",
        "        ''' ######################### First Optimizing the Discriminator ######################### '''\n",
        "\n",
        "        optimizer_discriminator.zero_grad()\n",
        "\n",
        "        fake_im_noise = torch.randn((batch_size, latent_dim), device=device) # creating a noisy data\n",
        "        fake_ims = generator(fake_im_noise) # passing the noisy data through the generator to get fake image\n",
        "        disc_real_pred = discriminator(real_ims) # passing real image to the discriminator\n",
        "        disc_fake_pred = discriminator(fake_ims.detach()) # passing fake image to the discriminator but we are detaching it so that gradients are not computed for generator and generator is not trained while training the discriminator\n",
        "\n",
        "        disc_loss = -torch.mean(torch.log(disc_real_pred.reshape(-1) + 0.0001) + torch.log(1. - disc_fake_pred.reshape(-1) + 0.0001) )\n",
        "\n",
        "        disc_loss.backward()\n",
        "        optimizer_discriminator.step()\n",
        "\n",
        "        mean_real_dis_preds.append(torch.nn.Sigmoid()(disc_real_pred).mean().item())\n",
        "        mean_fake_dis_preds.append(torch.nn.Sigmoid()(disc_fake_pred).mean().item())\n",
        "\n",
        "\n",
        "        ''' ######################### Second Optimizing the Generator ######################### '''\n",
        "        optimizer_generator.zero_grad()\n",
        "\n",
        "        fake_im_noise = torch.randn((batch_size, latent_dim), device=device) # creating a noisy data\n",
        "        fake_ims = generator(fake_im_noise) # passing through generator to create fake image\n",
        "        disc_fake_pred = discriminator(fake_ims) # passing through discriminator to classify it as fake or real\n",
        "\n",
        "        gen_fake_loss = -torch.mean(torch.log(disc_fake_pred.reshape(-1) + 0.0001))\n",
        "\n",
        "        gen_fake_loss.backward()\n",
        "        optimizer_generator.step()\n",
        "\n",
        "        generator_losses.append(gen_fake_loss.item())\n",
        "        discriminator_losses.append(disc_loss.item())\n",
        "\n",
        "        ''' ######################### Seeing how the generator is improving with training ######################### '''\n",
        "        if steps % 5 == 0:\n",
        "            with torch.no_grad():\n",
        "                generator.eval()\n",
        "\n",
        "                NUM_SAMPLES = 225\n",
        "                fake_im_noise = torch.randn((NUM_SAMPLES, latent_dim), device=device) # generating some noisy data\n",
        "                fake_ims = generator(fake_im_noise) # generating image using generator\n",
        "                ims = torch.clamp(fake_ims, -1., 1.).detach().cpu() # clamping the generated images\n",
        "                ims = 0.5*ims + 0.5 #detransforming the images from [-1,1] to [0,1]\n",
        "                grid = make_grid(ims, nrow=15)\n",
        "                img = torchvision.transforms.ToPILImage()(grid)\n",
        "                plt.imshow(img, cmap='gray') # now display the image here using matplot lib\n",
        "\n",
        "                generator.train()\n",
        "        steps += 1\n",
        "\n",
        "    print(f'''Finished epoch:{epoch + 1} | Generator Loss : {np.mean(generator_losses)} | Discriminator Loss : {np.mean(discriminator_losses)} | Discriminator real pred : {np.mean(mean_real_dis_preds)} | Discriminator fake pred : {np.mean(mean_fake_dis_preds)}''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FR5wjyvU-uDc"
      },
      "source": [
        "Key things to note in above training errors :\n",
        "\n",
        "1. First discriminator loss decreases while generator loss increases => because initially only discriminator is being trained\n",
        "2. Then the discriminator loss remains constant and the generator loss decreases => because now the discriminator is freezed and the generator is being trained"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXXMwiZaey40"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYQlXs6Q-xnR"
      },
      "outputs": [],
      "source": [
        "NUM_SAMPLES = 225\n",
        "fake_im_noise = torch.randn((NUM_SAMPLES, LATENT_DIM), device=device) # generating some noisy data\n",
        "generated_ims = generator(fake_im_noise) # generating image using generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4kZ8wTWhzfo"
      },
      "outputs": [],
      "source": [
        "generated_ims = torch.clamp(generated_ims, -1., 1.).detach().cpu() # clamping the generated images\n",
        "generated_ims = 0.5*generated_ims + 0.5 #detransforming the images from [-1,1] to [0,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuH_89PHex4E"
      },
      "outputs": [],
      "source": [
        "# now printing the predicted images\n",
        "grid = torchvision.utils.make_grid(generated_ims, nrow=15)\n",
        "img = torchvision.transforms.ToPILImage()(grid)\n",
        "plt.imshow(img, cmap='gray') # now display the image here using matplot lib"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "HJIBS7a8TK-O",
        "TNHZI1K6TOIE",
        "C_KJWVseZVD2",
        "sXXMwiZaey40"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}