{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYnF_gC-TNg2"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/khetansarvesh/CV/blob/main/data_augmentation/ddpm/dit_runner.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qiHWnpIsCARS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import yaml\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "import glob\n",
        "from torch.optim import Adam\n",
        "import cv2\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import torch\n",
        "from einops import rearrange, repeat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TLjIBUkmCBKc"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "    print('Using mps')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeLcFxcuCT_C"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RCiafg0eFQOF"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "M1F19gZ4FSoU",
        "outputId": "a7e86fbe-81f3-4121-a71e-c22eb8a5351a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 34.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.14MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 9.87MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.47MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]) # Define the transformation to normalize the data between 1 and -1 (mean = 0.5 and variance = 0.5 will transform to values between 1 and -1)\n",
        "mnist = datasets.MNIST(root='./data', train=True, transform=transform, download=True) # downloading the MNIST train dataset and then applying some transformations\n",
        "data_loader = DataLoader(dataset=mnist, batch_size=32, shuffle=True) # loading the downloaded dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QB7nTAZdCaSp"
      },
      "source": [
        "# Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0xCBU4g5TNg5"
      },
      "outputs": [],
      "source": [
        "def get_time_embedding(time_steps, # 1D array of timesteps eg [1,10,500,40,300]\n",
        "                       temb_dim): # dimension of vector to which each of these timestep needs to be converted to eg 128\n",
        "\n",
        "    # factor = 10000^(2i/d_model)\n",
        "    factor = 10000 ** ((torch.arange(start=0, end=temb_dim // 2, dtype=torch.float32, device=time_steps.device) / (temb_dim // 2)))\n",
        "\n",
        "    # pos / factor\n",
        "    t_emb = time_steps[:, None].repeat(1, temb_dim // 2) / factor\n",
        "\n",
        "    # now taking sin and cos of t_emb\n",
        "    return torch.cat([torch.sin(t_emb), torch.cos(t_emb)], dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "a1ZySva5TNg5"
      },
      "outputs": [],
      "source": [
        "class DIT(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.patch_embedding = nn.Sequential(nn.LayerNorm(1*4*4), nn.Linear(1*4*4, 768), nn.LayerNorm(768))\n",
        "        self.position_embedding = nn.Parameter(data=torch.randn(1, 49, 768),requires_grad=True)\n",
        "        self.embedding_dropout = nn.Dropout(p=0.1)\n",
        "\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer=nn.TransformerEncoderLayer(d_model=768,\n",
        "                                                                                                  nhead=2,\n",
        "                                                                                                  dim_feedforward=3072,\n",
        "                                                                                                  activation=\"gelu\",\n",
        "                                                                                                  batch_first=True,\n",
        "                                                                                                  norm_first=True), # Create a single Transformer Encoder Layer\n",
        "                                                        num_layers=2) # Stack it N times\n",
        "\n",
        "        # Final Linear Layer\n",
        "        self.proj_out = nn.Linear(768, 1*4*4)\n",
        "\n",
        "        # Time projection\n",
        "        self.ti_1 = nn.Linear(128, 400)\n",
        "        self.ti_2 = nn.Linear(400, 768)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "\n",
        "        # getting time embeddings\n",
        "        t_emb = get_time_embedding(torch.as_tensor(t).long(), 128)\n",
        "\n",
        "        # projecting time embeddings to D = 768 dimensions\n",
        "        time_proj1 = self.ti_1(t_emb)\n",
        "        time_proj2 = self.ti_2(time_proj1)\n",
        "\n",
        "        # Reshaping time embedding [32, 768, 1, 1] => [32, 768] => [32, 1, 768]\n",
        "        t_reshaped = time_proj2.squeeze(-2).squeeze(-1)\n",
        "        t_reshaped = t_reshaped.unsqueeze(1)\n",
        "\n",
        "\n",
        "        # 32, 1, 28, 28 -> 32, 1, 7*4, 7*4 -> 32, 1, 7, 7, 4, 4 -> 32, 7, 7, 4, 4, 1 -> 32, 7*7, 4*4*1 - > 32, num_patches, patch_dim\n",
        "        x = rearrange(x, 'b c (nh ph) (nw pw) -> b (nh nw) (ph pw c)', ph=4, pw=4)\n",
        "\n",
        "        # Create patch embedding for all images in the batch\n",
        "        x = self.patch_embedding(x)\n",
        "\n",
        "        #Add position embedding to patch embedding\n",
        "        x = self.position_embedding + x\n",
        "\n",
        "        # concatenating time embedding\n",
        "        x = torch.cat([x, t_reshaped], dim=1)\n",
        "\n",
        "        #Run embedding dropout\n",
        "        x = self.embedding_dropout(x)\n",
        "\n",
        "        #Pass patch, position and class embedding through transformer encoder layers (equations 2 & 3)\n",
        "        x = self.transformer_encoder(x)\n",
        "\n",
        "        # Unpatchify i.e. (B,patches,hidden_size) -> (B,patches,channels * patch_width * patch_height)\n",
        "        x = self.proj_out(x[:, 1:]) # note here we are ignore the first vector which represents the matured time embedding\n",
        "\n",
        "        # combine all the patches to form image\n",
        "        x = rearrange(x, 'b (nh nw) (ph pw c) -> b c (nh ph) (nw pw)',ph=4,pw=4,nw=7,nh=7)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "LcJUd1BfDM9P",
        "outputId": "8902cd48-6a72-4742-ff79-afcdaa6d973d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = DIT().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCApdvVwCbYM"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "wWrn_cc9JGDd"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "num_samples = 100\n",
        "num_grid_rows = 10\n",
        "\n",
        "model.train()\n",
        "optimizer = Adam(model.parameters(), lr = 0.0001) #optimizer = AdamW(model.parameters(), lr=1E-5, weight_decay=0)\n",
        "\n",
        "betas = torch.linspace(0.0001, 0.02, 1000).to(device) # creating a linear beta schedule for all the timestamps\n",
        "alpha_cum_prod = torch.cumprod(1. - betas, dim=0).to(device) # calculating alpha_bar for each timestamp\n",
        "sqrt_alpha_cum_prod = torch.sqrt(alpha_cum_prod).to(device) # calculating sqrt(alpha_bar) for each timestamp\n",
        "sqrt_one_minus_alpha_cum_prod = torch.sqrt(1 - alpha_cum_prod).to(device) # calculating sqrt(1-alpha_bar) for each timestamp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "ZOILwbJgDIyq"
      },
      "outputs": [],
      "source": [
        "# if os.path.exists(os.path.join('celebhq', 'dit_ckpt.pth')):\n",
        "#     print('Loaded DiT checkpoint')\n",
        "#     model.load_state_dict(torch.load(os.path.join('celebhq', 'dit_ckpt.pth'), map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D81HdHYpTNg6",
        "outputId": "6267bc6e-4c3a-499b-e685-ec4f1cc49885",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 43/1875 [01:57<1:21:28,  2.67s/it]"
          ]
        }
      ],
      "source": [
        "for epoch in range(40): # running for 40 epochs\n",
        "  losses = []\n",
        "\n",
        "  for im,_ in tqdm(data_loader):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    im = im.float().to(device)\n",
        "    noise = torch.randn_like(im).to(device) # sample random noise\n",
        "    t = torch.randint(low = 0, high = 1000, size = (im.shape[0],)).to(device) # sample a random timestamp for each image in the batch\n",
        "    noisy_im = torch.sqrt(alpha_cum_prod[t])[:, None, None, None].to(device) * im + torch.sqrt(1 - alpha_cum_prod[t])[:, None, None, None].to(device) * noise # add noise to image according to the timestamp\n",
        "    noise_pred = model(noisy_im, t) # predicting the added noise\n",
        "\n",
        "    loss = torch.nn.MSELoss()(noise_pred, noise) # loss fucntion\n",
        "    losses.append(loss.item())\n",
        "    loss.backward() # backpropagating the loss\n",
        "    optimizer.step()\n",
        "\n",
        "  print(f'Finished epoch:{epoch+1} | Loss : {np.mean(losses)}')\n",
        "  # torch.save(model.state_dict(), os.path.join('celebhq', 'dit_ckpt.pth'))\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mxVlvcZNWJJu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}