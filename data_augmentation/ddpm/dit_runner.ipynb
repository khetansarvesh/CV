{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qiHWnpIsCARS"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import yaml\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "import glob\n",
    "import cv2\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TLjIBUkmCBKc"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print('Using mps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GeLcFxcuCT_C"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RCiafg0eFQOF"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M1F19gZ4FSoU"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]) # Define the transformation to normalize the data between 1 and -1 (mean = 0.5 and variance = 0.5 will transform to values between 1 and -1)\n",
    "mnist = datasets.MNIST(root='./data', train=True, transform=transform, download=True) # downloading the MNIST train dataset and then applying some transformations\n",
    "data_loader = DataLoader(dataset=mnist, batch_size=32, shuffle=True) # loading the downloaded dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QB7nTAZdCaSp"
   },
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LcJUd1BfDM9P"
   },
   "outputs": [],
   "source": [
    "from dit_model import DIT\n",
    "model = DIT(\n",
    "            im_size=32,  #128\n",
    "            im_channels=4,  #3\n",
    "            config = {\n",
    "                        'patch_size' : 2,\n",
    "                        'num_layers' : 12,\n",
    "                        'hidden_size' : 768,\n",
    "                        'num_heads' : 12,\n",
    "                        'head_dim' : 64,\n",
    "                        'timestep_emb_dim' : 768\n",
    "                        }\n",
    "            ).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCApdvVwCbYM"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wWrn_cc9JGDd"
   },
   "outputs": [],
   "source": [
    "class LinearNoiseScheduler:\n",
    "    r\"\"\"\n",
    "    Class for the linear noise scheduler that is used in DDPM.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_timesteps, beta_start, beta_end):\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "\n",
    "        self.betas = torch.linspace(beta_start, beta_end, num_timesteps)\n",
    "        self.alphas = 1. - self.betas\n",
    "        self.alpha_cum_prod = torch.cumprod(self.alphas, dim=0)\n",
    "        self.sqrt_alpha_cum_prod = torch.sqrt(self.alpha_cum_prod)\n",
    "        self.sqrt_one_minus_alpha_cum_prod = torch.sqrt(1 - self.alpha_cum_prod)\n",
    "\n",
    "    def add_noise(self, original, noise, t):\n",
    "        r\"\"\"\n",
    "        Forward method for diffusion\n",
    "        :param original: Image on which noise is to be applied\n",
    "        :param noise: Random Noise Tensor (from normal dist)\n",
    "        :param t: timestep of the forward process of shape -> (B,)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        original_shape = original.shape\n",
    "        batch_size = original_shape[0]\n",
    "\n",
    "        sqrt_alpha_cum_prod = self.sqrt_alpha_cum_prod.to(original.device)[t].reshape(batch_size)\n",
    "        sqrt_one_minus_alpha_cum_prod = self.sqrt_one_minus_alpha_cum_prod.to(original.device)[t].reshape(batch_size)\n",
    "\n",
    "        # Reshape till (B,) becomes (B,1,1,1) if image is (B,C,H,W)\n",
    "        for _ in range(len(original_shape) - 1):\n",
    "            sqrt_alpha_cum_prod = sqrt_alpha_cum_prod.unsqueeze(-1)\n",
    "        for _ in range(len(original_shape) - 1):\n",
    "            sqrt_one_minus_alpha_cum_prod = sqrt_one_minus_alpha_cum_prod.unsqueeze(-1)\n",
    "\n",
    "        # Apply and Return Forward process equation\n",
    "        return (sqrt_alpha_cum_prod.to(original.device) * original\n",
    "                + sqrt_one_minus_alpha_cum_prod.to(original.device) * noise)\n",
    "\n",
    "    def sample_prev_timestep(self, xt, pred, t):\n",
    "        r\"\"\"\n",
    "            Use the noise prediction by model to get\n",
    "            xt-1 using xt and the noise predicted\n",
    "        :param xt: current timestep sample\n",
    "        :param pred: model noise prediction\n",
    "        :param t: current timestep we are at\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        x0 = ((xt - (self.sqrt_one_minus_alpha_cum_prod.to(xt.device)[t] * pred)) /\n",
    "              torch.sqrt(self.alpha_cum_prod.to(xt.device)[t]))\n",
    "        x0 = torch.clamp(x0, -1., 1.)\n",
    "\n",
    "        mean = xt - ((self.betas.to(xt.device)[t]) * pred) / (self.sqrt_one_minus_alpha_cum_prod.to(xt.device)[t])\n",
    "        mean = mean / torch.sqrt(self.alphas.to(xt.device)[t])\n",
    "\n",
    "        if t == 0:\n",
    "            return mean, x0\n",
    "        else:\n",
    "            variance = (1 - self.alpha_cum_prod.to(xt.device)[t - 1]) / (1.0 - self.alpha_cum_prod.to(xt.device)[t])\n",
    "            variance = variance * self.betas.to(xt.device)[t]\n",
    "            sigma = variance ** 0.5\n",
    "            z = torch.randn(xt.shape).to(xt.device)\n",
    "            return mean + sigma * z, x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fb-OVtoSJIKP"
   },
   "outputs": [],
   "source": [
    "scheduler = LinearNoiseScheduler(num_timesteps=1000, beta_start=0.0001, beta_end=0.02)\n",
    "optimizer = AdamW(model.parameters(), lr=1E-5, weight_decay=0)\n",
    "criterion = torch.nn.MSELoss()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZOILwbJgDIyq"
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join('celebhq', 'dit_ckpt.pth')):\n",
    "    print('Loaded DiT checkpoint')\n",
    "    model.load_state_dict(torch.load(os.path.join('celebhq', 'dit_ckpt.pth'), map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c1LKOJFFCqwd"
   },
   "outputs": [],
   "source": [
    "for epoch_idx in range(500):\n",
    "    losses = []\n",
    "    step_count = 0\n",
    "\n",
    "    for im in tqdm(data_loader):\n",
    "        step_count += 1\n",
    "        optimizer.zero_grad()\n",
    "        im = im.float().to(device)\n",
    "\n",
    "        mean, logvar = torch.chunk(im, 2, dim=1)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        im = mean + std * torch.randn(mean.shape).to(device=im.device)\n",
    "\n",
    "        # Sample random noise\n",
    "        noise = torch.randn_like(im).to(device)\n",
    "\n",
    "        # Sample timestep\n",
    "        t = torch.randint(0, 1000, (im.shape[0],)).to(device)\n",
    "\n",
    "        # Add noise to images according to timestep\n",
    "        noisy_im = scheduler.add_noise(im, noise, t)\n",
    "        pred = model(noisy_im, t)\n",
    "        loss = criterion(pred, noise)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    print('Finished epoch:{} | Loss : {:.4f}'.format(epoch_idx + 1,np.mean(losses)))\n",
    "    torch.save(model.state_dict(), os.path.join('celebhq', 'dit_ckpt.pth'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
