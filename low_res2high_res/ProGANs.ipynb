{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "qGEEYH7PTmhS",
        "BpxjnYhLTweQ",
        "U1gkW-WFTwUV"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GWEHjrtG6OqE"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from math import log2\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "from scipy.stats import truncnorm\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision.datasets import CelebA\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.benchmarks = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4teWu3V9F5J",
        "outputId": "6877c08c-fa8a-4298-b5ee-29eb77a3d809"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modelling**"
      ],
      "metadata": {
        "id": "gpx2YKDH6YVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "                                    nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1), nn.LeakyReLU(0.2),\n",
        "                                    nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1), nn.LeakyReLU(0.2),\n",
        "                                    )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "otBnif0VCUQ5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.initial = nn.Sequential(\n",
        "                                        nn.ConvTranspose2d(256, 256, 4, 1, 0), nn.LeakyReLU(0.2),\n",
        "                                        nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1), nn.LeakyReLU(0.2),\n",
        "                                    )\n",
        "\n",
        "        self.initial_rgb = nn.Conv2d(256, 3, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "\n",
        "        self.prog_blocks = nn.ModuleList([\n",
        "                                          ConvBlock(256, 256),\n",
        "                                          ConvBlock(256, 256),\n",
        "                                          ConvBlock(256, 256),\n",
        "                                          ConvBlock(256, 128),\n",
        "                                          ConvBlock(128, 64),\n",
        "                                          ConvBlock(64, 32),\n",
        "                                          ConvBlock(32, 16),\n",
        "                                          ConvBlock(16, 8),\n",
        "                                          ])\n",
        "        self.rgb_layers = nn.ModuleList([\n",
        "                                          self.initial_rgb,\n",
        "                                          nn.Conv2d(256, 3, kernel_size=1, stride=1, padding=0),\n",
        "                                          nn.Conv2d(256, 3, kernel_size=1, stride=1, padding=0),\n",
        "                                          nn.Conv2d(256, 3, kernel_size=1, stride=1, padding=0),\n",
        "                                          nn.Conv2d(128, 3, kernel_size=1, stride=1, padding=0),\n",
        "                                          nn.Conv2d(64, 3, kernel_size=1, stride=1, padding=0),\n",
        "                                          nn.Conv2d(32, 3, kernel_size=1, stride=1, padding=0),\n",
        "                                          nn.Conv2d(16, 3, kernel_size=1, stride=1, padding=0),\n",
        "                                          nn.Conv2d(8, 3, kernel_size=1, stride=1, padding=0)\n",
        "                                          ])\n",
        "\n",
        "    def forward(self, x, steps, alpha = 0.0001):\n",
        "        out = self.initial(x)\n",
        "\n",
        "        for step in range(steps):\n",
        "            upscaled = F.interpolate(out, scale_factor=2, mode=\"nearest\")\n",
        "            out = self.prog_blocks[step](upscaled)\n",
        "\n",
        "        final_upscaled = self.rgb_layers[steps - 1](upscaled)\n",
        "        final_out = self.rgb_layers[steps](out)\n",
        "        return torch.tanh(alpha * final_out + (1 - alpha) * final_upscaled)"
      ],
      "metadata": {
        "id": "GEHuHi2LeFPD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "\n",
        "        self.prog_blocks = nn.ModuleList([\n",
        "                                          ConvBlock(8, 16),\n",
        "                                          ConvBlock(16, 32),\n",
        "                                          ConvBlock(32, 64),\n",
        "                                          ConvBlock(64, 128),\n",
        "                                          ConvBlock(128, 256),\n",
        "                                          ConvBlock(256, 256),\n",
        "                                          ConvBlock(256, 256),\n",
        "                                          ConvBlock(256, 256)\n",
        "                                          ])\n",
        "\n",
        "\n",
        "        self.rgb_layers = nn.ModuleList([\n",
        "                                         nn.Conv2d(3, 8, kernel_size=1, stride=1, padding=0),\n",
        "                                         nn.Conv2d(3, 16, kernel_size=1, stride=1, padding=0),\n",
        "                                         nn.Conv2d(3, 32, kernel_size=1, stride=1, padding=0),\n",
        "                                         nn.Conv2d(3, 64, kernel_size=1, stride=1, padding=0),\n",
        "                                         nn.Conv2d(3, 128, kernel_size=1, stride=1, padding=0),\n",
        "                                         nn.Conv2d(3, 256, kernel_size=1, stride=1, padding=0),\n",
        "                                         nn.Conv2d(3, 256, kernel_size=1, stride=1, padding=0),\n",
        "                                         nn.Conv2d(3, 256, kernel_size=1, stride=1, padding=0),\n",
        "                                         nn.Conv2d(3, 256, kernel_size=1, stride=1, padding=0)\n",
        "        ])\n",
        "\n",
        "        self.leaky = nn.LeakyReLU(0.2)\n",
        "\n",
        "\n",
        "        self.avg_pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.final_block = nn.Sequential(\n",
        "                                            nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.LeakyReLU(0.2),\n",
        "                                            nn.Conv2d(256, 256, kernel_size=4, padding=0, stride=1),nn.LeakyReLU(0.2),\n",
        "                                            nn.Conv2d(256, 1, kernel_size=1, padding=0, stride=1)\n",
        "                                        )\n",
        "\n",
        "    def forward(self, x, steps):\n",
        "\n",
        "        cur_step = len(self.prog_blocks) - steps\n",
        "\n",
        "        out = self.leaky(self.rgb_layers[cur_step](x))\n",
        "\n",
        "        out = self.avg_pool(self.prog_blocks[cur_step](out))\n",
        "\n",
        "        for step in range(cur_step + 1, len(self.prog_blocks)):\n",
        "            out = self.prog_blocks[step](out)\n",
        "            out = self.avg_pool(out)\n",
        "\n",
        "        return self.final_block(out).view(out.shape[0], -1)"
      ],
      "metadata": {
        "id": "gm1rD5NH6Zfp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "qrIVaEyI6Zxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize models\n",
        "gen = Generator().to(DEVICE)\n",
        "critic = Discriminator().to(DEVICE)\n",
        "\n",
        "# setting the models to training mode\n",
        "gen.train()\n",
        "critic.train()\n",
        "\n",
        "# initialize optimizers\n",
        "opt_gen = optim.Adam(gen.parameters(), lr=1e-3, betas=(0.0, 0.99))\n",
        "opt_critic = optim.Adam(critic.parameters(), lr=1e-3, betas=(0.0, 0.99))\n",
        "\n",
        "scaler_critic = torch.cuda.amp.GradScaler()\n",
        "scaler_gen = torch.cuda.amp.GradScaler()"
      ],
      "metadata": {
        "id": "9JombZ3JUONp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training a model to generate 128*128\n"
      ],
      "metadata": {
        "id": "DXO_24MXTSjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 128\n",
        "batch_size = 16\n",
        "dataset = get_loader(image_size)\n",
        "loader = DataLoader( dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4)"
      ],
      "metadata": {
        "id": "fhgqvH5MUQoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(30):\n",
        "    print(f\"Epoch [{epoch+1}]\")\n",
        "\n",
        "\n",
        "    loop = tqdm(loader, leave=True)\n",
        "    for batch_idx, real in enumerate(loop):\n",
        "\n",
        "        real = real.to(DEVICE)\n",
        "\n",
        "\n",
        "        # Train Discriminator\n",
        "        noise = torch.randn(batch_size, 256, 1, 1).to(DEVICE)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            fake = gen(noise, 5, 1e-5)\n",
        "            critic_real = critic(real, 5)\n",
        "            critic_fake = critic(fake.detach(), 5)\n",
        "            loss_critic = 0.001*torch.mean(critic_real ** 2) - torch.mean(critic_real) + torch.mean(critic_fake)\n",
        "\n",
        "        opt_critic.zero_grad()\n",
        "        scaler_critic.scale(loss_critic).backward()\n",
        "        scaler_critic.step(opt_critic)\n",
        "        scaler_critic.update()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Train Generator\n",
        "        with torch.cuda.amp.autocast():\n",
        "            gen_fake = critic(fake, 5)\n",
        "            loss_gen = -torch.mean(gen_fake)\n",
        "\n",
        "        opt_gen.zero_grad()\n",
        "        scaler_gen.scale(loss_gen).backward()\n",
        "        scaler_gen.step(opt_gen)\n",
        "        scaler_gen.update()\n",
        "\n",
        "        loop.set_postfix(loss_critic=loss_critic.item())"
      ],
      "metadata": {
        "id": "4xfF337sUYRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training a model to generate 256 x 256"
      ],
      "metadata": {
        "id": "qGEEYH7PTmhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 256\n",
        "batch_size = 16\n",
        "dataset = get_loader(image_size)\n",
        "loader = DataLoader( dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4)"
      ],
      "metadata": {
        "id": "QWfPBJ4dVW7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(30):\n",
        "    print(f\"Epoch [{epoch+1}]\")\n",
        "\n",
        "\n",
        "    loop = tqdm(loader, leave=True)\n",
        "    for batch_idx, real in enumerate(loop):\n",
        "\n",
        "        real = real.to(DEVICE)\n",
        "\n",
        "\n",
        "        # Train Discriminator\n",
        "        noise = torch.randn(batch_size, 256, 1, 1).to(DEVICE)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            fake = gen(noise, 6, 1e-4)\n",
        "            critic_real = critic(real, 6)\n",
        "            critic_fake = critic(fake.detach(), 6)\n",
        "            loss_critic = 0.001*torch.mean(critic_real ** 2) - torch.mean(critic_real) + torch.mean(critic_fake)\n",
        "\n",
        "        opt_critic.zero_grad()\n",
        "        scaler_critic.scale(loss_critic).backward()\n",
        "        scaler_critic.step(opt_critic)\n",
        "        scaler_critic.update()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Train Generator\n",
        "        with torch.cuda.amp.autocast():\n",
        "            gen_fake = critic(fake, 6)\n",
        "            loss_gen = -torch.mean(gen_fake)\n",
        "\n",
        "        opt_gen.zero_grad()\n",
        "        scaler_gen.scale(loss_gen).backward()\n",
        "        scaler_gen.step(opt_gen)\n",
        "        scaler_gen.update()\n",
        "\n",
        "        loop.set_postfix(loss_critic=loss_critic.item())"
      ],
      "metadata": {
        "id": "EJxs9D9qTr4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training a model to generate 512 x 512"
      ],
      "metadata": {
        "id": "BpxjnYhLTweQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 512\n",
        "batch_size = 8\n",
        "dataset = get_loader(image_size)\n",
        "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4)"
      ],
      "metadata": {
        "id": "yPDk8uHfVcVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(30):\n",
        "    print(f\"Epoch [{epoch+1}]\")\n",
        "\n",
        "\n",
        "    loop = tqdm(loader, leave=True)\n",
        "    for batch_idx, real in enumerate(loop):\n",
        "\n",
        "        real = real.to(DEVICE)\n",
        "\n",
        "\n",
        "        # Train Discriminator\n",
        "        noise = torch.randn(batch_size, 256, 1, 1).to(DEVICE)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            fake = gen(noise, 7, 1e-3)\n",
        "            critic_real = critic(real, 7)\n",
        "            critic_fake = critic(fake.detach(), 7)\n",
        "            loss_critic = 0.001*torch.mean(critic_real ** 2) - torch.mean(critic_real) + torch.mean(critic_fake)\n",
        "\n",
        "        opt_critic.zero_grad()\n",
        "        scaler_critic.scale(loss_critic).backward()\n",
        "        scaler_critic.step(opt_critic)\n",
        "        scaler_critic.update()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Train Generator\n",
        "        with torch.cuda.amp.autocast():\n",
        "            gen_fake = critic(fake, 7)\n",
        "            loss_gen = -torch.mean(gen_fake)\n",
        "\n",
        "        opt_gen.zero_grad()\n",
        "        scaler_gen.scale(loss_gen).backward()\n",
        "        scaler_gen.step(opt_gen)\n",
        "        scaler_gen.update()\n",
        "\n",
        "        loop.set_postfix(loss_critic=loss_critic.item())"
      ],
      "metadata": {
        "id": "vfm6nNxfUAtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training a model to generate 1024*1024"
      ],
      "metadata": {
        "id": "U1gkW-WFTwUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 1024\n",
        "batch_size = 4\n",
        "dataset = get_loader(image_size)\n",
        "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4)"
      ],
      "metadata": {
        "id": "mo3DAoZUVhPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(30):\n",
        "    print(f\"Epoch [{epoch+1}]\")\n",
        "\n",
        "\n",
        "    loop = tqdm(loader, leave=True)\n",
        "    for batch_idx, real in enumerate(loop):\n",
        "\n",
        "        real = real.to(DEVICE)\n",
        "\n",
        "\n",
        "        # Train Discriminator\n",
        "        noise = torch.randn(batch_size, 256, 1, 1).to(DEVICE)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            fake = gen(noise, 8, 1e-2)\n",
        "            critic_real = critic(real, 8)\n",
        "            critic_fake = critic(fake.detach(), 8)\n",
        "            loss_critic = 0.001*torch.mean(critic_real ** 2) - torch.mean(critic_real) + torch.mean(critic_fake)\n",
        "\n",
        "        opt_critic.zero_grad()\n",
        "        scaler_critic.scale(loss_critic).backward()\n",
        "        scaler_critic.step(opt_critic)\n",
        "        scaler_critic.update()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Train Generator\n",
        "        with torch.cuda.amp.autocast():\n",
        "            gen_fake = critic(fake, 8)\n",
        "            loss_gen = -torch.mean(gen_fake)\n",
        "\n",
        "        opt_gen.zero_grad()\n",
        "        scaler_gen.scale(loss_gen).backward()\n",
        "        scaler_gen.step(opt_gen)\n",
        "        scaler_gen.update()\n",
        "\n",
        "        loop.set_postfix(loss_critic=loss_critic.item())"
      ],
      "metadata": {
        "id": "4dwyrdEB6asE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inference**\n",
        "Generating all images i.e.\n",
        "- 8 * 8,\n",
        "- 16 * 16,\n",
        "- 32*32,\n",
        "- 64 * 64,\n",
        "- 128 * 128,\n",
        "- 256 * 256,\n",
        "- 512 * 512,\n",
        "- 1024 * 1024"
      ],
      "metadata": {
        "id": "aDXbe_MN6a_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen.eval()\n",
        "for i in range(8):\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # input noise to the model\n",
        "        noise = torch.tensor(truncnorm.rvs(-truncation, truncation, size=(1, 256, 1, 1)), device=DEVICE, dtype=torch.float32)\n",
        "\n",
        "        # generating image using the generator\n",
        "        img = gen(noise, steps)\n",
        "\n",
        "        # denormalizing and saving the image\n",
        "        save_image(img*0.5+0.5, f\"saved_examples/img_{i}.png\")"
      ],
      "metadata": {
        "id": "W3hDyYcc7cJG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}