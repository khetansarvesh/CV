{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ap-5uzVEXb2"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/khetansarvesh/CV/blob/main/object_detection/yolo_version1/runner.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm==4.66.4\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.66.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Collecting torchvision==0.18.1\n",
      "  Downloading torchvision-0.18.1-cp312-cp312-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (from torchvision==0.18.1) (2.1.1)\n",
      "Collecting torch==2.3.1 (from torchvision==0.18.1)\n",
      "  Downloading torch-2.3.1-cp312-cp312-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from torchvision==0.18.1) (10.4.0)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.3.1->torchvision==0.18.1) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.3.1->torchvision==0.18.1) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.3.1->torchvision==0.18.1) (1.12)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.3.1->torchvision==0.18.1) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.3.1->torchvision==0.18.1) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.3.1->torchvision==0.18.1) (2024.2.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.1->torchvision==0.18.1)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.1->torchvision==0.18.1)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.1->torchvision==0.18.1)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.1->torchvision==0.18.1)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.1->torchvision==0.18.1)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.1->torchvision==0.18.1)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.1->torchvision==0.18.1)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.1->torchvision==0.18.1)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.1->torchvision==0.18.1)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.1->torchvision==0.18.1)\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.1->torchvision==0.18.1)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1->torchvision==0.18.1)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch==2.3.1->torchvision==0.18.1) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/codespace/.local/lib/python3.12/site-packages (from sympy->torch==2.3.1->torchvision==0.18.1) (1.3.0)\n",
      "Downloading torchvision-0.18.1-cp312-cp312-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.3.1-cp312-cp312-manylinux1_x86_64.whl (779.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Downloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.4.1+cpu\n",
      "    Uninstalling torch-2.4.1+cpu:\n",
      "      Successfully uninstalled torch-2.4.1+cpu\n",
      "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.77 nvidia-nvtx-cu12-12.1.105 torch-2.3.1 torchvision-0.18.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: torch==2.3.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (2.3.1)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.3.1) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.3.1) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.3.1) (1.12)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.3.1) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.3.1) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.3.1) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.3.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.3.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.3.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.3.1) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.3.1) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.3.1) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.3.1) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.3.1) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.3.1) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.3.1) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.3.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1) (12.6.77)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch==2.3.1) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/codespace/.local/lib/python3.12/site-packages (from sympy->torch==2.3.1) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Collecting albumentations==1.4.13\n",
      "  Downloading albumentations-1.4.13-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /home/codespace/.local/lib/python3.12/site-packages (from albumentations==1.4.13) (2.1.1)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /home/codespace/.local/lib/python3.12/site-packages (from albumentations==1.4.13) (1.14.1)\n",
      "Collecting scikit-image>=0.21.0 (from albumentations==1.4.13)\n",
      "  Downloading scikit_image-0.24.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: PyYAML in /home/codespace/.local/lib/python3.12/site-packages (from albumentations==1.4.13) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /home/codespace/.local/lib/python3.12/site-packages (from albumentations==1.4.13) (4.9.0)\n",
      "Collecting pydantic>=2.7.0 (from albumentations==1.4.13)\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Collecting albucore>=0.0.13 (from albumentations==1.4.13)\n",
      "  Downloading albucore-0.0.21-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting eval-type-backport (from albumentations==1.4.13)\n",
      "  Downloading eval_type_backport-0.2.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opencv-python-headless>=4.9.0.80 (from albumentations==1.4.13)\n",
      "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting stringzilla>=3.10.4 (from albucore>=0.0.13->albumentations==1.4.13)\n",
      "  Downloading stringzilla-3.10.7-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\n",
      "Collecting simsimd>=5.9.2 (from albucore>=0.0.13->albumentations==1.4.13)\n",
      "  Downloading simsimd-6.0.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (57 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.7.0->albumentations==1.4.13)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic>=2.7.0->albumentations==1.4.13)\n",
      "  Downloading pydantic_core-2.23.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: networkx>=2.8 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-image>=0.21.0->albumentations==1.4.13) (3.2.1)\n",
      "Requirement already satisfied: pillow>=9.1 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-image>=0.21.0->albumentations==1.4.13) (10.4.0)\n",
      "Collecting imageio>=2.33 (from scikit-image>=0.21.0->albumentations==1.4.13)\n",
      "  Downloading imageio-2.36.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image>=0.21.0->albumentations==1.4.13)\n",
      "  Downloading tifffile-2024.9.20-py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: packaging>=21 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-image>=0.21.0->albumentations==1.4.13) (24.1)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image>=0.21.0->albumentations==1.4.13)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Downloading albumentations-1.4.13-py3-none-any.whl (171 kB)\n",
      "Downloading albucore-0.0.21-py3-none-any.whl (12 kB)\n",
      "Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Downloading pydantic_core-2.23.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_image-0.24.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading eval_type_backport-0.2.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading imageio-2.36.0-py3-none-any.whl (315 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading simsimd-6.0.1-cp312-cp312-manylinux_2_28_x86_64.whl (680 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m680.9/680.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading stringzilla-3.10.7-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (295 kB)\n",
      "Downloading tifffile-2024.9.20-py3-none-any.whl (228 kB)\n",
      "Installing collected packages: stringzilla, simsimd, tifffile, pydantic-core, opencv-python-headless, lazy-loader, imageio, eval-type-backport, annotated-types, scikit-image, pydantic, albucore, albumentations\n",
      "Successfully installed albucore-0.0.21 albumentations-1.4.13 annotated-types-0.7.0 eval-type-backport-0.2.0 imageio-2.36.0 lazy-loader-0.4 opencv-python-headless-4.10.0.84 pydantic-2.9.2 pydantic-core-2.23.4 scikit-image-0.24.0 simsimd-6.0.1 stringzilla-3.10.7 tifffile-2024.9.20\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: Pillow==10.4.0 in /home/codespace/.local/lib/python3.12/site-packages (10.4.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Collecting opencv_python==4.10.0.84\n",
      "  Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home/codespace/.local/lib/python3.12/site-packages (from opencv_python==4.10.0.84) (2.1.1)\n",
      "Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opencv_python\n",
      "Successfully installed opencv_python-4.10.0.84\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Collecting einops==0.8.0\n",
      "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "Installing collected packages: einops\n",
      "Successfully installed einops-0.8.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install tqdm==4.66.4\n",
    "# !pip install torchvision==0.18.1\n",
    "# !pip install torch==2.3.1\n",
    "# !pip install albumentations==1.4.13\n",
    "# !pip install Pillow==10.4.0\n",
    "# !pip install opencv_python==4.10.0.84\n",
    "# !pip install einops==0.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "g8lyaXja9cvk"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np \n",
    "import yaml\n",
    "import csv\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import torch.nn as nn\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bENy4HHw-viz"
   },
   "outputs": [],
   "source": [
    "dataset_config = {\n",
    "                    'test_im_sets': ['data/VOC2007-test'],\n",
    "                    'num_classes' : 20,\n",
    "                    'im_size' : 448\n",
    "                    }\n",
    "\n",
    "train_config = {\n",
    "                'task_name': 'voc',\n",
    "                'seed': 1111,\n",
    "                'acc_steps': 1, # increase if you want to get gradients from >1 steps(kind of mimicking >1 batch size)\n",
    "                'log_steps': 100,\n",
    "                'num_epochs': 135,\n",
    "                'batch_size': 64,\n",
    "                'lr_steps': [ 50, 75, 100, 125 ],\n",
    "                'lr': 0.001,\n",
    "                'infer_conf_threshold' : 0.2,\n",
    "                'eval_conf_threshold' : 0.001,\n",
    "                'nms_threshold' : 0.5,\n",
    "                'ckpt_name': 'yolo_voc2007.pth'\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "d8f4Qy469taK"
   },
   "outputs": [],
   "source": [
    "seed = train_config['seed']\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wvvHVr0WEc-U",
    "outputId": "22cdbaaf-a1af-4f05-afd1-d0d6c3880768"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'CV'...\n",
      "remote: Enumerating objects: 820, done.\u001b[K\n",
      "remote: Counting objects: 100% (285/285), done.\u001b[K\n",
      "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
      "remote: Total 820 (delta 144), reused 274 (delta 136), pack-reused 535 (from 1)\u001b[K\n",
      "Receiving objects: 100% (820/820), 28.52 MiB | 46.14 MiB/s, done.\n",
      "Resolving deltas: 100% (441/441), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/khetansarvesh/CV.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TqbKXAjk9Uwk"
   },
   "source": [
    "# **Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-05 18:35:04--  http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
      "Resolving host.robots.ox.ac.uk (host.robots.ox.ac.uk)... 129.67.94.152\n",
      "Connecting to host.robots.ox.ac.uk (host.robots.ox.ac.uk)|129.67.94.152|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 460032000 (439M) [application/x-tar]\n",
      "Saving to: ‘VOCtrainval_06-Nov-2007.tar’\n",
      "\n",
      "VOCtrainval_06-Nov- 100%[===================>] 438.72M  36.2MB/s    in 13s     \n",
      "\n",
      "2024-11-05 18:35:18 (33.5 MB/s) - ‘VOCtrainval_06-Nov-2007.tar’ saved [460032000/460032000]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GETTING VOC2007 TRAIN DATASET and EXTRACTING TAR FILES                                                             \n",
    "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
    "!tar xf VOCtrainval_06-Nov-2007.tar\n",
    "\n",
    "# GETTING VOC2012 TRAIN DATASET and EXTRACTING TAR FILES                                                               \n",
    "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\n",
    "!tar xf VOCtrainval_11-May-2012.tar\n",
    "\n",
    "# GETTING VOC2007 TEST DATASET and EXTRACTING TAR FILES                                                             \n",
    "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar # \n",
    "!tar xf VOCtest_06-Nov-2007.tar\n",
    "\n",
    "## Gettting the images location for 2007 (both train and test) and 2012 (only train) dataset in txt files\n",
    "!wget https://pjreddie.com/media/files/voc_label.py\n",
    "!python voc_label.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training we will use train dataset from both 2007 and 2012 and hence we concatenate them and store in a new file called train.txt\n",
    "!cat 2007_train.txt 2007_val.txt 2012_*.txt > train.txt\n",
    "\n",
    "# creating training csv using train.txt\n",
    "read_train = open(\"train.txt\", \"r\").readlines()\n",
    "with open(\"train.csv\", mode=\"w\", newline=\"\") as train_file:\n",
    "    for line in read_train:\n",
    "        image_file = line.split(\"/\")[-1].replace(\"\\n\", \"\")\n",
    "        text_file = image_file.replace(\".jpg\", \".txt\")\n",
    "        data = [image_file, text_file]\n",
    "        writer = csv.writer(train_file)\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing we will only use test from 2007 and we store that in test.txt\n",
    "!cp 2007_test.txt test.txt\n",
    "\n",
    "# creating testing csv using test.txt\n",
    "read_train = open(\"test.txt\", \"r\").readlines()\n",
    "with open(\"test.csv\", mode=\"w\", newline=\"\") as train_file:\n",
    "    for line in read_train:\n",
    "        image_file = line.split(\"/\")[-1].replace(\"\\n\", \"\")\n",
    "        text_file = image_file.replace(\".jpg\", \".txt\")\n",
    "        data = [image_file, text_file]\n",
    "        writer = csv.writer(train_file)\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move txt files we won't be using to clean up a little bit\n",
    "!mkdir old_txt_files\n",
    "!mv 2007* 2012* old_txt_files/\n",
    "!mv test.txt old_txt_files/\n",
    "!mv train.txt old_txt_files/\n",
    "!mv VOCtest_06-Nov-2007.tar old_txt_files/\n",
    "!mv VOCtrainval_06-Nov-2007.tar old_txt_files/\n",
    "!mv VOCtrainval_11-May-2012.tar old_txt_files/\n",
    "\n",
    "# We don't need files in old_txt_files anymore, so deleting it\n",
    "!rm -rf old_txt_files/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: cannot stat 'VOCdevkit/*.jpg': No such file or directory\n",
      "mkdir: cannot create directory ‘data’: File exists\n",
      "mkdir: cannot create directory ‘data/images’: File exists\n",
      "mkdir: cannot create directory ‘data/labels’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir data                                                                              \n",
    "!mkdir data/images                                                                       \n",
    "!mkdir data/labels                                                                       \n",
    "                                                                                        \n",
    "!mv VOCdevkit/VOC2007/JPEGImages/*.jpg data/images/                                      \n",
    "!mv VOCdevkit/VOC2012/JPEGImages/*.jpg data/images/                                      \n",
    "!mv VOCdevkit/VOC2007/labels/*.txt data/labels/                                          \n",
    "!mv VOCdevkit/VOC2012/labels/*.txt data/labels/ \n",
    "\n",
    "# We don't need VOCdevkit folder anymore, can remove it in order to save some space \n",
    "!rm -rf VOCdevkit/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "riigy5NRE-KW"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libGL.so.1: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# from CV.object_detection.yolo_version1.dataset import VOCDataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VOCDataset\n\u001b[1;32m      3\u001b[0m voc \u001b[38;5;241m=\u001b[39m VOCDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/workspaces/CV/object_detection/yolo_version1/dataset.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01malbumentations\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01malbu\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/albumentations/__init__.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01malbumentations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheck_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_for_updates\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maugmentations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserialization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/albumentations/augmentations/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblur\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblur\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcrops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/albumentations/augmentations/blur/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/albumentations/augmentations/blur/functional.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ceil\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Literal, Sequence\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01malbucore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clipped, maybe_process_in_chunks, preserve_channel_dim\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/cv2/__init__.py:181\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra Python code for\u001b[39m\u001b[38;5;124m\"\u001b[39m, submodule, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis loaded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpenCV loader: DONE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbootstrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/cv2/__init__.py:153\u001b[0m, in \u001b[0;36mbootstrap\u001b[0;34m()\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRelink everything from native cv2 module to cv2 package\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    151\u001b[0m py_module \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 153\u001b[0m native_module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcv2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv2\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m py_module\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28msetattr\u001b[39m(py_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_native\u001b[39m\u001b[38;5;124m\"\u001b[39m, native_module)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/importlib/__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mImportError\u001b[0m: libGL.so.1: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "from CV.object_detection.yolo_version1.dataset import VOCDataset\n",
    "voc = VOCDataset('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tz7wkgcU9SSC"
   },
   "outputs": [],
   "source": [
    "def collate_function(data):\n",
    "    return list(zip(*data))\n",
    "\n",
    "train_dataset = DataLoader(voc, batch_size=train_config['batch_size'], shuffle=True, collate_fn=collate_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nK5pM4US9hCi"
   },
   "source": [
    "# **Modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XATLzq6j_c7Q"
   },
   "outputs": [],
   "source": [
    "class YOLOV1(nn.Module):\n",
    "\n",
    "    def __init__(self, im_size, num_classes, model_config):\n",
    "        super(YOLOV1, self).__init__()\n",
    "        self.im_size = im_size\n",
    "        self.im_channels = model_config['im_channels']\n",
    "        self.backbone_channels = model_config['backbone_channels']\n",
    "        self.yolo_conv_channels = model_config['yolo_conv_channels']\n",
    "        self.conv_spatial_size = model_config['conv_spatial_size']\n",
    "        self.leaky_relu_slope = model_config['leaky_relu_slope']\n",
    "        self.yolo_fc_hidden_dim = model_config['fc_dim']\n",
    "        self.yolo_fc_dropout_prob = model_config['fc_dropout']\n",
    "        self.use_conv = model_config['use_conv']\n",
    "        self.S = model_config['S']\n",
    "        self.B = model_config['B']\n",
    "        self.C = num_classes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ###################\n",
    "        # Backbone Layers # resnet34 pretrained on 224x224 images from Imagenet\n",
    "        ###################\n",
    "        backbone = torchvision.models.resnet34(weights=torchvision.models.ResNet34_Weights.IMAGENET1K_V1)\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            backbone.conv1,\n",
    "            backbone.bn1,\n",
    "            backbone.relu,\n",
    "            backbone.maxpool,\n",
    "            backbone.layer1,\n",
    "            backbone.layer2,\n",
    "            backbone.layer3,\n",
    "            backbone.layer4,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #########################\n",
    "        # Detection Conv Layers # 4 Conv,Batchnorm,LeakyReLU Layers for Yolo Detection Head\n",
    "        #########################\n",
    "        self.conv_yolo_layers = nn.Sequential(\n",
    "            nn.Conv2d(self.backbone_channels,\n",
    "                      self.yolo_conv_channels,\n",
    "                      3,\n",
    "                      padding=1,\n",
    "                      bias=False),\n",
    "            nn.BatchNorm2d(self.yolo_conv_channels),\n",
    "            nn.LeakyReLU(self.leaky_relu_slope),\n",
    "            nn.Conv2d(self.yolo_conv_channels,\n",
    "                      self.yolo_conv_channels,\n",
    "                      3,\n",
    "                      stride=2,\n",
    "                      padding=1,\n",
    "                      bias=False),\n",
    "            nn.BatchNorm2d(self.yolo_conv_channels),\n",
    "            nn.LeakyReLU(self.leaky_relu_slope),\n",
    "            nn.Conv2d(self.yolo_conv_channels,\n",
    "                      self.yolo_conv_channels,\n",
    "                      3,\n",
    "                      padding=1,\n",
    "                      bias=False),\n",
    "            nn.BatchNorm2d(self.yolo_conv_channels),\n",
    "            nn.LeakyReLU(self.leaky_relu_slope),\n",
    "            nn.Conv2d(self.yolo_conv_channels,\n",
    "                      self.yolo_conv_channels,\n",
    "                      3,\n",
    "                      padding=1,\n",
    "                      bias=False),\n",
    "            nn.BatchNorm2d(self.yolo_conv_channels),\n",
    "            nn.LeakyReLU(self.leaky_relu_slope)\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #######################\n",
    "        # Detection Layers #\n",
    "        '''\n",
    "        Fc layers with final layer having S*S*(5B+C) output dimensions\n",
    "        Final layer predicts [\n",
    "            x_offset_box1,y_offset_box1,sqrt_w_box1,sqrt_h_box1,conf_box1, # box-1 params\n",
    "            ...,\n",
    "            x_offset_boxB,y_offset_boxB,sqrt_w_boxB,sqrt_h_boxB,conf_boxB, # box-B params\n",
    "            p1, p2, ...., pC-1, pC  # class conditional probabilities\n",
    "        ] for each S*S grid cell\n",
    "        '''\n",
    "        #######################\n",
    "        if self.use_conv:\n",
    "            self.fc_yolo_layers = nn.Sequential(\n",
    "                nn.Conv2d(self.yolo_conv_channels, 5 * self.B + self.C, 1),\n",
    "            )\n",
    "        else:\n",
    "            self.fc_yolo_layers = nn.Sequential(\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(self.conv_spatial_size * self.conv_spatial_size *\n",
    "                          self.yolo_conv_channels,\n",
    "                          self.yolo_fc_hidden_dim),\n",
    "                nn.LeakyReLU(self.leaky_relu_slope),\n",
    "                nn.Dropout(self.yolo_fc_dropout_prob),\n",
    "                nn.Linear(self.yolo_fc_hidden_dim,\n",
    "                          self.S * self.S * (5 * self.B + self.C)),\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = self.conv_yolo_layers(out)\n",
    "        out = self.fc_yolo_layers(out)\n",
    "        if self.use_conv:\n",
    "            # Reshape conv output to Batch x S x S x (5B+C)\n",
    "            out = out.permute(0, 2, 3, 1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ab714p1x9iGu"
   },
   "outputs": [],
   "source": [
    "model_config = {\n",
    "                'im_channels' : 3,\n",
    "                'backbone_channels' : 512,\n",
    "                'conv_spatial_size' : 7,\n",
    "                'yolo_conv_channels' : 1024,\n",
    "                'leaky_relu_slope' : 0.1,\n",
    "                'fc_dim' : 4096,\n",
    "                'fc_dropout' : 0.5,\n",
    "                'S' : 7,\n",
    "                'B' : 2,\n",
    "                'use_sigmoid' : True,\n",
    "                'use_conv' : True\n",
    "                }\n",
    "\n",
    "yolo_model = YOLOV1(im_size=dataset_config['im_size'],\n",
    "                    num_classes=dataset_config['num_classes'],\n",
    "                    model_config=model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dzSSurx9WIT"
   },
   "source": [
    "# **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GjlnswVcFNYO"
   },
   "outputs": [],
   "source": [
    "yolo_model.train()\n",
    "yolo_model.to(device)\n",
    "if os.path.exists(os.path.join(train_config['task_name'],\n",
    "                                train_config['ckpt_name'])):\n",
    "    print('Loading checkpoint as one exists')\n",
    "    yolo_model.load_state_dict(torch.load(\n",
    "        os.path.join(train_config['task_name'],\n",
    "                        train_config['ckpt_name']),\n",
    "        map_location=device))\n",
    "if not os.path.exists(train_config['task_name']):\n",
    "    os.mkdir(train_config['task_name'])\n",
    "\n",
    "optimizer = torch.optim.SGD(lr=train_config['lr'],\n",
    "                            params=filter(lambda p: p.requires_grad,\n",
    "                                            yolo_model.parameters()),\n",
    "                            weight_decay=5E-4,\n",
    "                            momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QyzIS6gY-CK4"
   },
   "outputs": [],
   "source": [
    "scheduler = MultiStepLR(optimizer, milestones=train_config['lr_steps'], gamma=0.5)\n",
    "\n",
    "from CV.object_detection.yolo_version1.loss import YOLOV1Loss\n",
    "criterion = YOLOV1Loss()\n",
    "\n",
    "acc_steps = train_config['acc_steps']\n",
    "num_epochs = train_config['num_epochs']\n",
    "steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qhzGFRTb9Wqy"
   },
   "outputs": [],
   "source": [
    "\n",
    "for epoch_idx in range(num_epochs):\n",
    "    losses = []\n",
    "    optimizer.zero_grad()\n",
    "    for idx, (ims, targets, _) in enumerate(tqdm(train_dataset)):\n",
    "        yolo_targets = torch.cat([\n",
    "            target['yolo_targets'].unsqueeze(0).float().to(device)\n",
    "            for target in targets], dim=0)\n",
    "        im = torch.cat([im.unsqueeze(0).float().to(device) for im in ims], dim=0)\n",
    "        yolo_preds = yolo_model(im)\n",
    "        loss = criterion(yolo_preds, yolo_targets, use_sigmoid=model_config['use_sigmoid'])\n",
    "        loss = loss / acc_steps\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "        if (idx + 1) % acc_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        if steps % train_config['log_steps'] == 0:\n",
    "            print('Loss : {:.4f}'.format(np.mean(losses)))\n",
    "        if torch.isnan(loss):\n",
    "            print('Loss is becoming nan. Exiting')\n",
    "            exit(0)\n",
    "        steps += 1\n",
    "    print('Finished epoch {}'.format(epoch_idx+1))\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    scheduler.step()\n",
    "    torch.save(yolo_model.state_dict(), os.path.join(train_config['task_name'],\n",
    "                                                        train_config['ckpt_name']))\n",
    "print('Done Training...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39jLK65H9XA5"
   },
   "source": [
    "# **Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oGSmE1FV9YxX"
   },
   "outputs": [],
   "source": [
    "from CV.object_detection.yolo_version1.infer import infer, evaluate_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pR7CzaxFFnEJ"
   },
   "outputs": [],
   "source": [
    "infer(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OlYjShK0GBBx"
   },
   "outputs": [],
   "source": [
    "evaluate_map(args)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "TqbKXAjk9Uwk",
    "nK5pM4US9hCi",
    "2dzSSurx9WIT",
    "39jLK65H9XA5"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
