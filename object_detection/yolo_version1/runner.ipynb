{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ap-5uzVEXb2"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/khetansarvesh/CV/blob/main/object_detection/yolo_version1/runner.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "g8lyaXja9cvk"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm # tqdm==4.66.4\n",
    "import numpy as np # numpy==2.0.1\n",
    "import yaml # PyYAML==6.0.1\n",
    "# einops==0.8.0\n",
    "# opencv_python==4.10.0.84\n",
    "# Pillow==10.4.0\n",
    "# albumentations==1.4.13\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import torch.nn as nn # torch==2.3.1\n",
    "import torchvision # torchvision==0.18.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bENy4HHw-viz"
   },
   "outputs": [],
   "source": [
    "dataset_config = {\n",
    "                    'test_im_sets': ['data/VOC2007-test'],\n",
    "                    'num_classes' : 20,\n",
    "                    'im_size' : 448\n",
    "                    }\n",
    "\n",
    "train_config = {\n",
    "                'task_name': 'voc',\n",
    "                'seed': 1111,\n",
    "                'acc_steps': 1, # increase if you want to get gradients from >1 steps(kind of mimicking >1 batch size)\n",
    "                'log_steps': 100,\n",
    "                'num_epochs': 135,\n",
    "                'batch_size': 64,\n",
    "                'lr_steps': [ 50, 75, 100, 125 ],\n",
    "                'lr': 0.001,\n",
    "                'infer_conf_threshold' : 0.2,\n",
    "                'eval_conf_threshold' : 0.001,\n",
    "                'nms_threshold' : 0.5,\n",
    "                'ckpt_name': 'yolo_voc2007.pth'\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "d8f4Qy469taK"
   },
   "outputs": [],
   "source": [
    "seed = train_config['seed']\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wvvHVr0WEc-U",
    "outputId": "22cdbaaf-a1af-4f05-afd1-d0d6c3880768"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'CV'...\n",
      "remote: Enumerating objects: 808, done.\u001b[K\n",
      "remote: Counting objects: 100% (273/273), done.\u001b[K\n",
      "remote: Compressing objects: 100% (212/212), done.\u001b[K\n",
      "remote: Total 808 (delta 140), reused 80 (delta 36), pack-reused 535 (from 1)\u001b[K\n",
      "Receiving objects: 100% (808/808), 28.11 MiB | 35.98 MiB/s, done.\n",
      "Resolving deltas: 100% (437/437), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/khetansarvesh/CV.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TqbKXAjk9Uwk"
   },
   "source": [
    "# **Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "riigy5NRE-KW"
   },
   "outputs": [],
   "source": [
    "from CV.object_detection.yolo_version1.dataset import VOCDataset\n",
    "voc = VOCDataset('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tz7wkgcU9SSC"
   },
   "outputs": [],
   "source": [
    "def collate_function(data):\n",
    "    return list(zip(*data))\n",
    "\n",
    "train_dataset = DataLoader(voc, batch_size=train_config['batch_size'], shuffle=True, collate_fn=collate_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nK5pM4US9hCi"
   },
   "source": [
    "# **Modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XATLzq6j_c7Q"
   },
   "outputs": [],
   "source": [
    "class YOLOV1(nn.Module):\n",
    "\n",
    "    def __init__(self, im_size, num_classes, model_config):\n",
    "        super(YOLOV1, self).__init__()\n",
    "        self.im_size = im_size\n",
    "        self.im_channels = model_config['im_channels']\n",
    "        self.backbone_channels = model_config['backbone_channels']\n",
    "        self.yolo_conv_channels = model_config['yolo_conv_channels']\n",
    "        self.conv_spatial_size = model_config['conv_spatial_size']\n",
    "        self.leaky_relu_slope = model_config['leaky_relu_slope']\n",
    "        self.yolo_fc_hidden_dim = model_config['fc_dim']\n",
    "        self.yolo_fc_dropout_prob = model_config['fc_dropout']\n",
    "        self.use_conv = model_config['use_conv']\n",
    "        self.S = model_config['S']\n",
    "        self.B = model_config['B']\n",
    "        self.C = num_classes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ###################\n",
    "        # Backbone Layers # resnet34 pretrained on 224x224 images from Imagenet\n",
    "        ###################\n",
    "        backbone = torchvision.models.resnet34(weights=torchvision.models.ResNet34_Weights.IMAGENET1K_V1)\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            backbone.conv1,\n",
    "            backbone.bn1,\n",
    "            backbone.relu,\n",
    "            backbone.maxpool,\n",
    "            backbone.layer1,\n",
    "            backbone.layer2,\n",
    "            backbone.layer3,\n",
    "            backbone.layer4,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #########################\n",
    "        # Detection Conv Layers # 4 Conv,Batchnorm,LeakyReLU Layers for Yolo Detection Head\n",
    "        #########################\n",
    "        self.conv_yolo_layers = nn.Sequential(\n",
    "            nn.Conv2d(self.backbone_channels,\n",
    "                      self.yolo_conv_channels,\n",
    "                      3,\n",
    "                      padding=1,\n",
    "                      bias=False),\n",
    "            nn.BatchNorm2d(self.yolo_conv_channels),\n",
    "            nn.LeakyReLU(self.leaky_relu_slope),\n",
    "            nn.Conv2d(self.yolo_conv_channels,\n",
    "                      self.yolo_conv_channels,\n",
    "                      3,\n",
    "                      stride=2,\n",
    "                      padding=1,\n",
    "                      bias=False),\n",
    "            nn.BatchNorm2d(self.yolo_conv_channels),\n",
    "            nn.LeakyReLU(self.leaky_relu_slope),\n",
    "            nn.Conv2d(self.yolo_conv_channels,\n",
    "                      self.yolo_conv_channels,\n",
    "                      3,\n",
    "                      padding=1,\n",
    "                      bias=False),\n",
    "            nn.BatchNorm2d(self.yolo_conv_channels),\n",
    "            nn.LeakyReLU(self.leaky_relu_slope),\n",
    "            nn.Conv2d(self.yolo_conv_channels,\n",
    "                      self.yolo_conv_channels,\n",
    "                      3,\n",
    "                      padding=1,\n",
    "                      bias=False),\n",
    "            nn.BatchNorm2d(self.yolo_conv_channels),\n",
    "            nn.LeakyReLU(self.leaky_relu_slope)\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #######################\n",
    "        # Detection Layers #\n",
    "        '''\n",
    "        Fc layers with final layer having S*S*(5B+C) output dimensions\n",
    "        Final layer predicts [\n",
    "            x_offset_box1,y_offset_box1,sqrt_w_box1,sqrt_h_box1,conf_box1, # box-1 params\n",
    "            ...,\n",
    "            x_offset_boxB,y_offset_boxB,sqrt_w_boxB,sqrt_h_boxB,conf_boxB, # box-B params\n",
    "            p1, p2, ...., pC-1, pC  # class conditional probabilities\n",
    "        ] for each S*S grid cell\n",
    "        '''\n",
    "        #######################\n",
    "        if self.use_conv:\n",
    "            self.fc_yolo_layers = nn.Sequential(\n",
    "                nn.Conv2d(self.yolo_conv_channels, 5 * self.B + self.C, 1),\n",
    "            )\n",
    "        else:\n",
    "            self.fc_yolo_layers = nn.Sequential(\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(self.conv_spatial_size * self.conv_spatial_size *\n",
    "                          self.yolo_conv_channels,\n",
    "                          self.yolo_fc_hidden_dim),\n",
    "                nn.LeakyReLU(self.leaky_relu_slope),\n",
    "                nn.Dropout(self.yolo_fc_dropout_prob),\n",
    "                nn.Linear(self.yolo_fc_hidden_dim,\n",
    "                          self.S * self.S * (5 * self.B + self.C)),\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = self.conv_yolo_layers(out)\n",
    "        out = self.fc_yolo_layers(out)\n",
    "        if self.use_conv:\n",
    "            # Reshape conv output to Batch x S x S x (5B+C)\n",
    "            out = out.permute(0, 2, 3, 1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ab714p1x9iGu"
   },
   "outputs": [],
   "source": [
    "model_config = {\n",
    "                'im_channels' : 3,\n",
    "                'backbone_channels' : 512,\n",
    "                'conv_spatial_size' : 7,\n",
    "                'yolo_conv_channels' : 1024,\n",
    "                'leaky_relu_slope' : 0.1,\n",
    "                'fc_dim' : 4096,\n",
    "                'fc_dropout' : 0.5,\n",
    "                'S' : 7,\n",
    "                'B' : 2,\n",
    "                'use_sigmoid' : True,\n",
    "                'use_conv' : True\n",
    "                }\n",
    "\n",
    "yolo_model = YOLOV1(im_size=dataset_config['im_size'],\n",
    "                    num_classes=dataset_config['num_classes'],\n",
    "                    model_config=model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dzSSurx9WIT"
   },
   "source": [
    "# **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GjlnswVcFNYO"
   },
   "outputs": [],
   "source": [
    "yolo_model.train()\n",
    "yolo_model.to(device)\n",
    "if os.path.exists(os.path.join(train_config['task_name'],\n",
    "                                train_config['ckpt_name'])):\n",
    "    print('Loading checkpoint as one exists')\n",
    "    yolo_model.load_state_dict(torch.load(\n",
    "        os.path.join(train_config['task_name'],\n",
    "                        train_config['ckpt_name']),\n",
    "        map_location=device))\n",
    "if not os.path.exists(train_config['task_name']):\n",
    "    os.mkdir(train_config['task_name'])\n",
    "\n",
    "optimizer = torch.optim.SGD(lr=train_config['lr'],\n",
    "                            params=filter(lambda p: p.requires_grad,\n",
    "                                            yolo_model.parameters()),\n",
    "                            weight_decay=5E-4,\n",
    "                            momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QyzIS6gY-CK4"
   },
   "outputs": [],
   "source": [
    "scheduler = MultiStepLR(optimizer, milestones=train_config['lr_steps'], gamma=0.5)\n",
    "\n",
    "from CV.object_detection.yolo_version1.loss import YOLOV1Loss\n",
    "criterion = YOLOV1Loss()\n",
    "\n",
    "acc_steps = train_config['acc_steps']\n",
    "num_epochs = train_config['num_epochs']\n",
    "steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qhzGFRTb9Wqy"
   },
   "outputs": [],
   "source": [
    "\n",
    "for epoch_idx in range(num_epochs):\n",
    "    losses = []\n",
    "    optimizer.zero_grad()\n",
    "    for idx, (ims, targets, _) in enumerate(tqdm(train_dataset)):\n",
    "        yolo_targets = torch.cat([\n",
    "            target['yolo_targets'].unsqueeze(0).float().to(device)\n",
    "            for target in targets], dim=0)\n",
    "        im = torch.cat([im.unsqueeze(0).float().to(device) for im in ims], dim=0)\n",
    "        yolo_preds = yolo_model(im)\n",
    "        loss = criterion(yolo_preds, yolo_targets, use_sigmoid=model_config['use_sigmoid'])\n",
    "        loss = loss / acc_steps\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "        if (idx + 1) % acc_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        if steps % train_config['log_steps'] == 0:\n",
    "            print('Loss : {:.4f}'.format(np.mean(losses)))\n",
    "        if torch.isnan(loss):\n",
    "            print('Loss is becoming nan. Exiting')\n",
    "            exit(0)\n",
    "        steps += 1\n",
    "    print('Finished epoch {}'.format(epoch_idx+1))\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    scheduler.step()\n",
    "    torch.save(yolo_model.state_dict(), os.path.join(train_config['task_name'],\n",
    "                                                        train_config['ckpt_name']))\n",
    "print('Done Training...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39jLK65H9XA5"
   },
   "source": [
    "# **Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oGSmE1FV9YxX"
   },
   "outputs": [],
   "source": [
    "from CV.object_detection.yolo_version1.infer import infer, evaluate_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pR7CzaxFFnEJ"
   },
   "outputs": [],
   "source": [
    "infer(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OlYjShK0GBBx"
   },
   "outputs": [],
   "source": [
    "evaluate_map(args)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "TqbKXAjk9Uwk",
    "nK5pM4US9hCi",
    "2dzSSurx9WIT",
    "39jLK65H9XA5"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
