{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX6u-2Ce_FjI"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/khetansarvesh/CV/blob/main/style_transfer/cycle_gan.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "GmE1wyis_FjK",
        "outputId": "fe81b0bf-8914-4c39-b8ba-fc54a35167d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import copy\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "\n",
        "import kagglehub\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "from torchvision.utils import save_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "5K4vNqA9_FjL",
        "outputId": "e3965ef6-2b41-402e-f3ed-2916ba259c5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"PYTHONHASHSEED\"] = str(42)\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a folder to store images while training\n",
        "!mkdir saved_images"
      ],
      "metadata": {
        "id": "banBT7zkSaLt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZK8se5R_FjM"
      },
      "source": [
        "# **Dataset**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading the dataset from kaggle : https://www.kaggle.com/datasets/suyashdamle/cyclegan\n",
        "path = kagglehub.dataset_download(\"suyashdamle/cyclegan\")\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "UwDiTJQuNek-",
        "outputId": "a8af9f75-258c-4f3b-c03c-db24956066d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.5)\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/suyashdamle/cyclegan/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "-NAiqZdG_FjM"
      },
      "outputs": [],
      "source": [
        "class HorseZebraDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.base = \"/root/.cache/kagglehub/datasets/suyashdamle/cyclegan/versions/1/horse2zebra/horse2zebra/\"\n",
        "        self.horse_images = os.listdir(self.base + \"trainA\")\n",
        "        self.zebra_images = os.listdir(self.base + \"trainB\")\n",
        "        self.zebra_len = len(self.zebra_images)\n",
        "        self.horse_len = len(self.horse_images)\n",
        "\n",
        "    def __len__(self):\n",
        "        return max(self.zebra_len, self.horse_len)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # finding image index\n",
        "        zebra_img = self.zebra_images[index % self.zebra_len]\n",
        "        horse_img = self.horse_images[index % self.horse_len]\n",
        "\n",
        "        # finding image path\n",
        "        horse_path = os.path.join(self.base + \"trainA\", horse_img)\n",
        "        zebra_path = os.path.join(self.base + \"trainB\", zebra_img)\n",
        "\n",
        "        # opening image and storing in array\n",
        "        zebra_img = np.array(Image.open(zebra_path).convert(\"RGB\"))\n",
        "        horse_img = np.array(Image.open(horse_path).convert(\"RGB\"))\n",
        "\n",
        "        # performing transformations on the images zebra and horses\n",
        "        transform = A.Compose(\n",
        "                                [\n",
        "                                    A.Resize(width=256, height=256),\n",
        "                                    A.HorizontalFlip(p=0.5),\n",
        "                                    A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255),\n",
        "                                    ToTensorV2(),\n",
        "                                ],\n",
        "                                additional_targets={\"image0\": \"image\"},\n",
        "                            )\n",
        "        augmentations = transform(image=zebra_img, image0=horse_img)\n",
        "\n",
        "        return augmentations[\"image\"], augmentations[\"image0\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "KOCIJQnS_FjM",
        "outputId": "ca891438-9f0f-4220-efed-00e2c0f43bcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "dataset = HorseZebraDataset()\n",
        "loader = DataLoader( dataset, batch_size=1, shuffle=True, num_workers=4, pin_memory=True)\n",
        "\n",
        "# val_dataset = HorseZebraDataset(root_horse=\"cyclegan_test/horse1\", root_zebra=\"cyclegan_test/zebra1\", transform=transforms)\n",
        "# val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1q4iktYp_FjN"
      },
      "source": [
        "# **Modelling**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, img_channels=3, num_features=64, num_residuals=9):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "                                        nn.Conv2d(3, 64, 7, 1, 3, padding_mode=\"reflect\"), nn.InstanceNorm2d(64), nn.ReLU(inplace=True),\n",
        "                                        nn.Conv2d(64, 128, 3, 2, 1, padding_mode=\"reflect\"), nn.InstanceNorm2d(128), nn.ReLU(inplace=True),\n",
        "                                        nn.Conv2d(128, 256, 3, 2, 1, padding_mode=\"reflect\"), nn.InstanceNorm2d(256), nn.ReLU(inplace=True),\n",
        "                                        nn.ConvTranspose2d(256, 128, 3, 2, 1, 1), nn.InstanceNorm2d(128),nn.ReLU(inplace=True),\n",
        "                                        nn.ConvTranspose2d(128, 64, 3, 2, 1, 1), nn.InstanceNorm2d(64),nn.ReLU(inplace=True),\n",
        "                                        nn.Conv2d(64, 3, 7, 1, 3, padding_mode=\"reflect\")\n",
        "                        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.tanh(self.model(x))"
      ],
      "metadata": {
        "id": "l-5CcB70_wGL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "39rQV6fD_FjN"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "                                    nn.Conv2d(3, 64, 4, 2, 1, padding_mode=\"reflect\"), nn.LeakyReLU(0.2, inplace=True),\n",
        "                                    nn.Conv2d(64, 128, 4, 2, 1, bias = True, padding_mode=\"reflect\"), nn.InstanceNorm2d(128), nn.LeakyReLU(0.2, inplace=True),\n",
        "                                    nn.Conv2d(128, 256, 4, 2, 1, bias = True, padding_mode=\"reflect\"), nn.InstanceNorm2d(256), nn.LeakyReLU(0.2, inplace=True),\n",
        "                                    nn.Conv2d(256, 512, 4, 1, 1, bias = True, padding_mode=\"reflect\"), nn.InstanceNorm2d(512), nn.LeakyReLU(0.2, inplace=True),\n",
        "                                    nn.Conv2d(512, 1, 4, 1, 1, padding_mode=\"reflect\")\n",
        "                                  )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.sigmoid(self.model(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3s0P3lc_FjO"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "IKX4YLcC_FjO"
      },
      "outputs": [],
      "source": [
        "# initialing models\n",
        "disc_H = Discriminator().to(DEVICE)\n",
        "disc_Z = Discriminator().to(DEVICE)\n",
        "gen_Z = Generator().to(DEVICE)\n",
        "gen_H = Generator().to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "lYSvDSYb_FjO",
        "outputId": "356bbca4-5c2b-43a1-fa8d-363eb4b4eb23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-64327fce3dd7>:10: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  g_scaler = torch.cuda.amp.GradScaler()\n",
            "<ipython-input-10-64327fce3dd7>:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  d_scaler = torch.cuda.amp.GradScaler()\n"
          ]
        }
      ],
      "source": [
        "# defining optimizers\n",
        "opt_disc = optim.Adam(list(disc_H.parameters()) + list(disc_Z.parameters()),lr=1e-5,betas=(0.5, 0.999),)\n",
        "opt_gen = optim.Adam(list(gen_Z.parameters()) + list(gen_H.parameters()), lr=1e-5, betas=(0.5, 0.999),)\n",
        "\n",
        "# defining loss functions\n",
        "l1 = nn.L1Loss()\n",
        "mse = nn.MSELoss()\n",
        "\n",
        "# scalers\n",
        "g_scaler = torch.cuda.amp.GradScaler()\n",
        "d_scaler = torch.cuda.amp.GradScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "tVOlt8-2_FjO",
        "outputId": "52d21d30-bc99-4429-f841-587b024061d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1334 [00:00<?, ?it/s]<ipython-input-11-0784ebd8dd33>:19: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "<ipython-input-11-0784ebd8dd33>:54: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "100%|██████████| 1334/1334 [02:15<00:00,  9.88it/s, H_fake=0.406, H_real=0.593]\n",
            "100%|██████████| 1334/1334 [02:09<00:00, 10.27it/s, H_fake=0.39, H_real=0.607]\n",
            "100%|██████████| 1334/1334 [02:10<00:00, 10.25it/s, H_fake=0.368, H_real=0.625]\n",
            "100%|██████████| 1334/1334 [02:09<00:00, 10.27it/s, H_fake=0.357, H_real=0.636]\n",
            "100%|██████████| 1334/1334 [02:10<00:00, 10.25it/s, H_fake=0.351, H_real=0.643]\n",
            "100%|██████████| 1334/1334 [02:09<00:00, 10.26it/s, H_fake=0.337, H_real=0.66]\n",
            "100%|██████████| 1334/1334 [02:09<00:00, 10.33it/s, H_fake=0.327, H_real=0.671]\n",
            "100%|██████████| 1334/1334 [02:09<00:00, 10.32it/s, H_fake=0.318, H_real=0.679]\n",
            "100%|██████████| 1334/1334 [02:09<00:00, 10.34it/s, H_fake=0.315, H_real=0.686]\n",
            "100%|██████████| 1334/1334 [02:09<00:00, 10.30it/s, H_fake=0.307, H_real=0.689]\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(10):\n",
        "    H_reals = 0\n",
        "    H_fakes = 0\n",
        "    loop = tqdm(loader, leave=True)\n",
        "\n",
        "    for idx, (zebra, horse) in enumerate(loop):\n",
        "\n",
        "        # sending inputs to device at hand\n",
        "        zebra, horse = zebra.to(DEVICE), horse.to(DEVICE)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        '''Train Discriminators H and Z while keeping Generator Constant'''\n",
        "        with torch.cuda.amp.autocast():\n",
        "            fake_horse = gen_H(zebra)\n",
        "            D_H_real = disc_H(horse)\n",
        "            D_H_fake = disc_H(fake_horse.detach())\n",
        "            H_reals += D_H_real.mean().item()\n",
        "            H_fakes += D_H_fake.mean().item()\n",
        "            D_H_real_loss = mse(D_H_real, torch.ones_like(D_H_real))\n",
        "            D_H_fake_loss = mse(D_H_fake, torch.zeros_like(D_H_fake))\n",
        "            D_H_loss = D_H_real_loss + D_H_fake_loss\n",
        "\n",
        "            fake_zebra = gen_Z(horse)\n",
        "            D_Z_real = disc_Z(zebra)\n",
        "            D_Z_fake = disc_Z(fake_zebra.detach())\n",
        "            D_Z_real_loss = mse(D_Z_real, torch.ones_like(D_Z_real))\n",
        "            D_Z_fake_loss = mse(D_Z_fake, torch.zeros_like(D_Z_fake))\n",
        "            D_Z_loss = D_Z_real_loss + D_Z_fake_loss\n",
        "\n",
        "            D_loss = (D_H_loss + D_Z_loss) / 2\n",
        "\n",
        "        opt_disc.zero_grad()\n",
        "        d_scaler.scale(D_loss).backward()\n",
        "        d_scaler.step(opt_disc)\n",
        "        d_scaler.update()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        '''Train Generators H and Z while keeping Discriminator Constant'''\n",
        "        with torch.cuda.amp.autocast():\n",
        "            # adversarial loss for both generators\n",
        "            D_H_fake = disc_H(fake_horse)\n",
        "            D_Z_fake = disc_Z(fake_zebra)\n",
        "            loss_G_H = mse(D_H_fake, torch.ones_like(D_H_fake))\n",
        "            loss_G_Z = mse(D_Z_fake, torch.ones_like(D_Z_fake))\n",
        "\n",
        "            # cycle loss\n",
        "            cycle_zebra = gen_Z(fake_horse)\n",
        "            cycle_horse = gen_H(fake_zebra)\n",
        "            cycle_zebra_loss = l1(zebra, cycle_zebra)\n",
        "            cycle_horse_loss = l1(horse, cycle_horse)\n",
        "\n",
        "            # add all togethor\n",
        "            G_loss = loss_G_Z + loss_G_H + 10*cycle_zebra_loss + 10*cycle_horse_loss\n",
        "\n",
        "        opt_gen.zero_grad()\n",
        "        g_scaler.scale(G_loss).backward()\n",
        "        g_scaler.step(opt_gen)\n",
        "        g_scaler.update()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        if idx % 200 == 0:\n",
        "            save_image(fake_horse * 0.5 + 0.5, f\"saved_images/horse_{idx}.png\")\n",
        "            save_image(fake_zebra * 0.5 + 0.5, f\"saved_images/zebra_{idx}.png\")\n",
        "\n",
        "\n",
        "\n",
        "        loop.set_postfix(H_real=H_reals / (idx + 1), H_fake=H_fakes / (idx + 1))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "AcPkOeBWFwdW",
        "bvwSlJZsF1tS"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}