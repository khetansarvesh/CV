{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/khetansarvesh/CV/blob/main/style_transfer/cycle_gan.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "Download dataset from here : https://www.kaggle.com/datasets/suyashdamle/cyclegan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class HorseZebraDataset(Dataset):\n",
    "    def __init__(self, root_zebra, root_horse, transform=None):\n",
    "        self.root_zebra = root_zebra\n",
    "        self.root_horse = root_horse\n",
    "        self.transform = transform\n",
    "\n",
    "        self.zebra_images = os.listdir(root_zebra)\n",
    "        self.horse_images = os.listdir(root_horse)\n",
    "        self.length_dataset = max(len(self.zebra_images), len(self.horse_images)) # 1000, 1500\n",
    "        self.zebra_len = len(self.zebra_images)\n",
    "        self.horse_len = len(self.horse_images)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length_dataset\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        zebra_img = self.zebra_images[index % self.zebra_len]\n",
    "        horse_img = self.horse_images[index % self.horse_len]\n",
    "\n",
    "        zebra_path = os.path.join(self.root_zebra, zebra_img)\n",
    "        horse_path = os.path.join(self.root_horse, horse_img)\n",
    "\n",
    "        zebra_img = np.array(Image.open(zebra_path).convert(\"RGB\"))\n",
    "        horse_img = np.array(Image.open(horse_path).convert(\"RGB\"))\n",
    "\n",
    "        if self.transform:\n",
    "            augmentations = self.transform(image=zebra_img, image0=horse_img)\n",
    "            zebra_img = augmentations[\"image\"]\n",
    "            horse_img = augmentations[\"image0\"]\n",
    "\n",
    "        return zebra_img, horse_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(width=256, height=256),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    "    additional_targets={\"image0\": \"image\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset = HorseZebraDataset( root_horse=\"data/train/horses\", root_zebra=\"data/train\" + \"/zebras\", transform=transforms)\n",
    "loader = DataLoader( dataset, batch_size=1, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "val_dataset = HorseZebraDataset(root_horse=\"cyclegan_test/horse1\", root_zebra=\"cyclegan_test/zebra1\", transform=transforms)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        layers.append( nn.Conv2d(3, 64, 4, 2, 1, padding_mode=\"reflect\"), nn.LeakyReLU(0.2, inplace=True) )\n",
    "        layers.append( nn.Conv2d(64, 128, 4, 2, 1, bias = True, padding_mode=\"reflect\"), nn.InstanceNorm2d(128), nn.LeakyReLU(0.2, inplace=True) )\n",
    "        layers.append( nn.Conv2d(128, 256, 4, 2, 1, bias = True, padding_mode=\"reflect\"), nn.InstanceNorm2d(256), nn.LeakyReLU(0.2, inplace=True) )\n",
    "        layers.append( nn.Conv2d(256, 512, 4, 1, 1, bias = True, padding_mode=\"reflect\"), nn.InstanceNorm2d(512), nn.LeakyReLU(0.2, inplace=True) )\n",
    "        layers.append(nn.Conv2d(512, 1, 4, 1, 1, padding_mode=\"reflect\"))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.model(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, down=True, use_act=True, **kwargs):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, padding_mode=\"reflect\", **kwargs)\n",
    "            if down\n",
    "            else nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True) if use_act else nn.Identity(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(ConvBlock(channels, channels, kernel_size=3, padding=1),ConvBlock(channels, channels, use_act=False, kernel_size=3, padding=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, img_channels, num_features=64, num_residuals=9):\n",
    "        super().__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                img_channels,\n",
    "                num_features,\n",
    "                kernel_size=7,\n",
    "                stride=1,\n",
    "                padding=3,\n",
    "                padding_mode=\"reflect\",\n",
    "            ),\n",
    "            nn.InstanceNorm2d(num_features),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.down_blocks = nn.ModuleList(\n",
    "            [\n",
    "                ConvBlock(\n",
    "                    num_features, num_features * 2, kernel_size=3, stride=2, padding=1\n",
    "                ),\n",
    "                ConvBlock(\n",
    "                    num_features * 2,\n",
    "                    num_features * 4,\n",
    "                    kernel_size=3,\n",
    "                    stride=2,\n",
    "                    padding=1,\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        self.res_blocks = nn.Sequential(\n",
    "            *[ResidualBlock(num_features * 4) for _ in range(num_residuals)]\n",
    "        )\n",
    "        self.up_blocks = nn.ModuleList(\n",
    "            [\n",
    "                ConvBlock(\n",
    "                    num_features * 4,\n",
    "                    num_features * 2,\n",
    "                    down=False,\n",
    "                    kernel_size=3,\n",
    "                    stride=2,\n",
    "                    padding=1,\n",
    "                    output_padding=1,\n",
    "                ),\n",
    "                ConvBlock(\n",
    "                    num_features * 2,\n",
    "                    num_features * 1,\n",
    "                    down=False,\n",
    "                    kernel_size=3,\n",
    "                    stride=2,\n",
    "                    padding=1,\n",
    "                    output_padding=1,\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.last = nn.Conv2d(\n",
    "            num_features * 1,\n",
    "            img_channels,\n",
    "            kernel_size=7,\n",
    "            stride=1,\n",
    "            padding=3,\n",
    "            padding_mode=\"reflect\",\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial(x)\n",
    "        for layer in self.down_blocks:\n",
    "            x = layer(x)\n",
    "        x = self.res_blocks(x)\n",
    "        for layer in self.up_blocks:\n",
    "            x = layer(x)\n",
    "        return torch.tanh(self.last(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# initialing models\n",
    "disc_H = Discriminator(in_channels=3).to(config.DEVICE)\n",
    "disc_Z = Discriminator(in_channels=3).to(config.DEVICE)\n",
    "gen_Z = Generator(img_channels=3, num_residuals=9).to(config.DEVICE)\n",
    "gen_H = Generator(img_channels=3, num_residuals=9).to(config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# defining optimizers\n",
    "opt_disc = optim.Adam(list(disc_H.parameters()) + list(disc_Z.parameters()),lr=1e-5,betas=(0.5, 0.999),)\n",
    "opt_gen = optim.Adam(list(gen_Z.parameters()) + list(gen_H.parameters()), lr=1e-5, betas=(0.5, 0.999),)\n",
    "\n",
    "# defining loss functions\n",
    "l1 = nn.L1Loss()\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "# scalers\n",
    "g_scaler = torch.cuda.amp.GradScaler()\n",
    "d_scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    H_reals = 0\n",
    "    H_fakes = 0\n",
    "    loop = tqdm(loader, leave=True)\n",
    "\n",
    "    for idx, (zebra, horse) in enumerate(loop):\n",
    "\n",
    "        # sending inputs to device at hand\n",
    "        zebra, horse = zebra.to(config.DEVICE), horse.to(config.DEVICE)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        '''Train Discriminators H and Z while keeping Generator Constant'''\n",
    "        with torch.cuda.amp.autocast():\n",
    "            fake_horse = gen_H(zebra)\n",
    "            D_H_real = disc_H(horse)\n",
    "            D_H_fake = disc_H(fake_horse.detach())\n",
    "            H_reals += D_H_real.mean().item()\n",
    "            H_fakes += D_H_fake.mean().item()\n",
    "            D_H_real_loss = mse(D_H_real, torch.ones_like(D_H_real))\n",
    "            D_H_fake_loss = mse(D_H_fake, torch.zeros_like(D_H_fake))\n",
    "            D_H_loss = D_H_real_loss + D_H_fake_loss\n",
    "\n",
    "            fake_zebra = gen_Z(horse)\n",
    "            D_Z_real = disc_Z(zebra)\n",
    "            D_Z_fake = disc_Z(fake_zebra.detach())\n",
    "            D_Z_real_loss = mse(D_Z_real, torch.ones_like(D_Z_real))\n",
    "            D_Z_fake_loss = mse(D_Z_fake, torch.zeros_like(D_Z_fake))\n",
    "            D_Z_loss = D_Z_real_loss + D_Z_fake_loss\n",
    "\n",
    "            # put it togethor\n",
    "            D_loss = (D_H_loss + D_Z_loss) / 2\n",
    "\n",
    "        opt_disc.zero_grad()\n",
    "        d_scaler.scale(D_loss).backward()\n",
    "        d_scaler.step(opt_disc)\n",
    "        d_scaler.update()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        '''Train Generators H and Z while keeping Discriminator Constant'''\n",
    "        with torch.cuda.amp.autocast():\n",
    "            # adversarial loss for both generators\n",
    "            D_H_fake = disc_H(fake_horse)\n",
    "            D_Z_fake = disc_Z(fake_zebra)\n",
    "            loss_G_H = mse(D_H_fake, torch.ones_like(D_H_fake))\n",
    "            loss_G_Z = mse(D_Z_fake, torch.ones_like(D_Z_fake))\n",
    "\n",
    "            # cycle loss\n",
    "            cycle_zebra = gen_Z(fake_horse)\n",
    "            cycle_horse = gen_H(fake_zebra)\n",
    "            cycle_zebra_loss = l1(zebra, cycle_zebra)\n",
    "            cycle_horse_loss = l1(horse, cycle_horse)\n",
    "\n",
    "            # identity loss (remove these for efficiency if you set lambda_identity=0)\n",
    "            identity_zebra = gen_Z(zebra)\n",
    "            identity_horse = gen_H(horse)\n",
    "            identity_zebra_loss = l1(zebra, identity_zebra)\n",
    "            identity_horse_loss = l1(horse, identity_horse)\n",
    "\n",
    "            # add all togethor\n",
    "            G_loss = (\n",
    "                loss_G_Z\n",
    "                + loss_G_H\n",
    "                + cycle_zebra_loss * 10\n",
    "                + cycle_horse_loss * 10\n",
    "                + identity_horse_loss * 0.0\n",
    "                + identity_zebra_loss * 0.0\n",
    "            )\n",
    "\n",
    "        opt_gen.zero_grad()\n",
    "        g_scaler.scale(G_loss).backward()\n",
    "        g_scaler.step(opt_gen)\n",
    "        g_scaler.update()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if idx % 200 == 0:\n",
    "            save_image(fake_horse * 0.5 + 0.5, f\"saved_images/horse_{idx}.png\")\n",
    "            save_image(fake_zebra * 0.5 + 0.5, f\"saved_images/zebra_{idx}.png\")\n",
    "\n",
    "\n",
    "\n",
    "        loop.set_postfix(H_real=H_reals / (idx + 1), H_fake=H_fakes / (idx + 1))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP6g5rQoH+gTQh6Ez8+N5Po",
   "collapsed_sections": [
    "AcPkOeBWFwdW",
    "bvwSlJZsF1tS"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
